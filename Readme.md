# Segmentation SÃ©mantique Binaire pour Conduite Autonome

Projet de segmentation sÃ©mantique **binaire** (Traversable vs. ObstruÃ©) pour vÃ©hicules autonomes utilisant CARLA, PyTorch et l'architecture ENet.

## ğŸ¯ Objectif

Le modÃ¨le apprend Ã  **reconnaÃ®tre et comprendre** tous les objets de la scÃ¨ne (voitures, piÃ©tons, routes, bÃ¢timents, etc.) pour ensuite les classifier en **2 catÃ©gories** :
- ğŸŸ¢ **Zone Traversable** (route, trottoir, terrain, etc.)
- ğŸ”´ **Zone ObstruÃ©e** (voitures, piÃ©tons, bÃ¢timents, etc.)

### Architecture du systÃ¨me

```
CARLA (23 classes sÃ©mantiques) 
    â†“
Collecte des donnÃ©es avec annotations multi-classes
    â†“
EntraÃ®nement du modÃ¨le (apprend les 23 classes)
    â†“
Conversion automatique vers 2 classes binaires
    â†“
Sortie finale : Traversable (vert) / ObstruÃ© (rouge)
```

## ğŸ“‹ Table des matiÃ¨res

- [Installation](#installation)
- [Collecte de donnÃ©es](#1-collecte-de-donnÃ©es-depuis-carla)
- [PrÃ©paration des donnÃ©es](#2-prÃ©paration-des-donnÃ©es)
- [EntraÃ®nement](#3-entraÃ®nement)
- [Ã‰valuation](#4-Ã©valuation)
- [Test temps rÃ©el](#5-test-en-temps-rÃ©el-dans-carla)
- [Structure du projet](#structure-du-projet)
- [Adaptation aux conditions extrÃªmes](#adaptation-aux-conditions-extrÃªmes)

## ğŸš€ Installation

### PrÃ©requis

- Python 3.8+
- CUDA 11.8+ (pour GPU, fortement recommandÃ©)
- CARLA Simulator 0.9.13+
- 16GB RAM minimum
- GPU avec 6GB+ VRAM recommandÃ©

### Installation des dÃ©pendances

```bash
# Cloner le projet
git clone <votre-repo>
cd projet_segmentation

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Installer CARLA Python API
pip install carla==0.9.13
```

### Configuration CARLA

```bash
# TÃ©lÃ©charger CARLA depuis https://github.com/carla-simulator/carla/releases
# Extraire et lancer le serveur:

cd /chemin/vers/CARLA
./CarlaUE4.sh  # Linux
# ou
CarlaUE4.exe  # Windows
```

## ğŸ“Š Workflow Complet

### 1. Collecte de donnÃ©es depuis CARLA

Le script collecte automatiquement des images RGB avec leurs masques sÃ©mantiques (23 classes).

```bash
# Lancer CARLA d'abord !

# Collecte simple (500 images)
python carla_scripts/collect_images.py \
    --output data/collected \
    --num_images 500

# Collecte diversifiÃ©e (diffÃ©rentes mÃ©tÃ©os)
python carla_scripts/collect_images.py \
    --output data/collected \
    --num_images 500 \
    --diverse

# Options avancÃ©es
python carla_scripts/collect_images.py \
    --output data/collected \
    --num_images 1000 \
    --diverse \
    --width 800 \
    --height 600 \
    --host localhost \
    --port 2000
```

**Sortie** :
- `data/collected/images/` : Images RGB
- `data/collected/masks/` : Masques sÃ©mantiques (.npy et .png)

### 2. PrÃ©paration des donnÃ©es

Organisez vos donnÃ©es en train/val/test (80/10/10 typiquement) :

```bash
# CrÃ©er la structure
mkdir -p data/train/images data/train/masks
mkdir -p data/val/images data/val/masks
mkdir -p data/test/images data/test/masks

# DÃ©placer les fichiers manuellement ou avec un script
# Exemple : 80% train, 10% val, 10% test
```

**Important** : La conversion multi-classe â†’ binaire se fait **automatiquement** pendant l'entraÃ®nement !

### 3. EntraÃ®nement

#### 3.1 EntraÃ®nement rapide (test)

```bash
python training/train.py \
    --model enet \
    --train_images data/train/images \
    --train_masks data/train/masks \
    --val_images data/val/images \
    --val_masks data/val/masks \
    --epochs 10 \
    --batch_size 4 \
    --experiment_name test_run
```

#### 3.2 EntraÃ®nement complet

```bash
# Avec ENet (recommandÃ© pour temps rÃ©el)
python training/train.py \
    --model enet \
    --train_images data/train/images \
    --train_masks data/train/masks \
    --val_images data/val/images \
    --val_masks data/val/masks \
    --epochs 100 \
    --batch_size 8 \
    --lr 5e-4 \
    --image_size 512 \
    --weighted_loss \
    --experiment_name enet_binary_v1

# Avec U-Net (meilleure prÃ©cision)
python training/train.py \
    --model unet \
    --train_images data/train/images \
    --train_masks data/train/masks \
    --val_images data/val/images \
    --val_masks data/val/masks \
    --epochs 100 \
    --batch_size 4 \
    --experiment_name unet_binary_v1
```

#### 3.3 Reprendre un entraÃ®nement

```bash
python training/train.py \
    --model enet \
    --resume checkpoints/enet_binary_v1_last.pth \
    --epochs 150 \
    --experiment_name enet_binary_v1_continued
```

#### 3.4 Visualisation avec TensorBoard

```bash
tensorboard --logdir runs/
# Ouvrir http://localhost:6006
```

### 4. Ã‰valuation

#### 4.1 Ã‰valuation sur le dataset de test

```bash
python training/evaluate.py \
    --checkpoint checkpoints/enet_binary_v1_best.pth \
    --model enet \
    --images data/test/images \
    --masks data/test/masks \
    --batch_size 8 \
    --save_predictions \
    --output evaluation_results
```

**Sortie** :
- MÃ©triques dÃ©taillÃ©es (mIoU, Pixel Accuracy, Dice)
- Visualisations dans `evaluation_results/`

#### 4.2 Ã‰valuation sur une image unique

```bash
python training/evaluate.py \
    --checkpoint checkpoints/enet_binary_v1_best.pth \
    --model enet \
    --single_image data/test/images/test_001.png \
    --single_mask data/test/masks/test_001.npy \
    --output evaluation_results
```

#### 4.3 Comparaison de plusieurs modÃ¨les

```bash
python training/evaluate.py \
    --compare checkpoints/enet_binary_v1_best.pth \
              checkpoints/unet_binary_v1_best.pth \
    --compare_types enet unet \
    --images data/test/images \
    --masks data/test/masks
```

### 5. Test en temps rÃ©el dans CARLA

```bash
# Lancer CARLA d'abord !

# Test basique
python carla_scripts/test_realtime.py \
    --checkpoint checkpoints/enet_binary_v1_best.pth \
    --model enet

# Test avec enregistrement vidÃ©o
python carla_scripts/test_realtime.py \
    --checkpoint checkpoints/enet_binary_v1_best.pth \
    --model enet \
    --save_video \
    --video_path results/demo.avi

# Options avancÃ©es
python carla_scripts/test_realtime.py \
    --checkpoint checkpoints/enet_binary_v1_best.pth \
    --model enet \
    --camera_width 1024 \
    --camera_height 768 \
    --display_width 1920 \
    --display_height 1080 \
    --save_video \
    --video_path results/demo_hd.avi
```

**ContrÃ´les** :
- `q` : Quitter
- `s` : Sauvegarder la frame actuelle

## ğŸ“ Structure du projet

```
projet_segmentation/
â”œâ”€â”€ config.py                 # Configuration des classes et mapping binaire
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â”‚
â”œâ”€â”€ models/                   # Architectures des modÃ¨les
â”‚   â”œâ”€â”€ enet.py              # ENet (temps rÃ©el)
â”‚   â””â”€â”€ unet.py              # U-Net (prÃ©cision)
â”‚
â”œâ”€â”€ data/                     # Gestion des donnÃ©es
â”‚   â””â”€â”€ dataset.py           # Dataset avec conversion automatique
â”‚
â”œâ”€â”€ training/                 # Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ train.py             # EntraÃ®nement principal
â”‚   â””â”€â”€ evaluate.py          # Ã‰valuation
â”‚
â”œâ”€â”€ utils/                    # Utilitaires
â”‚   â”œâ”€â”€ metrics.py           # Calcul des mÃ©triques
â”‚   â””â”€â”€ visualization.py     # Visualisation
â”‚
â”œâ”€â”€ carla_scripts/           # Scripts CARLA
â”‚   â”œâ”€â”€ collect_images.py   # Collecte de donnÃ©es
â”‚   â””â”€â”€ test_realtime.py    # Test temps rÃ©el
â”‚
â”œâ”€â”€ checkpoints/             # ModÃ¨les sauvegardÃ©s
â”œâ”€â”€ runs/                    # Logs TensorBoard
â””â”€â”€ data/                    # DonnÃ©es
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ images/
    â”‚   â””â”€â”€ masks/
    â”œâ”€â”€ val/
    â”‚   â”œâ”€â”€ images/
    â”‚   â””â”€â”€ masks/
    â””â”€â”€ test/
        â”œâ”€â”€ images/
        â””â”€â”€ masks/
```

## ğŸ”„ Mapping des classes

Le fichier `config.py` dÃ©finit le mapping des 23 classes CARLA vers 2 classes binaires :

### Classes CARLA â†’ Binaire

**Traversable (0 - Vert)** :
- Road (route)
- RoadLine (ligne de route)
- Sidewalk (trottoir)
- Ground (sol)
- Bridge (pont)
- RailTrack (rail)
- Terrain (terrain)

**ObstruÃ© (1 - Rouge)** :
- Building (bÃ¢timent)
- Fence (barriÃ¨re)
- Pedestrian (piÃ©ton)
- Pole (poteau)
- Vegetation (vÃ©gÃ©tation)
- Vehicles (vÃ©hicules)
- Wall (mur)
- TrafficSign (panneau)
- Sky (ciel)
- TrafficLight (feu)
- Et autres obstacles

## ğŸŒ¦ï¸ Adaptation aux conditions extrÃªmes

### Phase 1 : EntraÃ®nement de base

Utilisez d'abord la collecte diversifiÃ©e pour obtenir des donnÃ©es dans diffÃ©rentes mÃ©tÃ©os :

```bash
python carla_scripts/collect_images.py \
    --output data/diverse \
    --num_images 1000 \
    --diverse
```

### Phase 2 : Data augmentation intensive

Le dataset inclut dÃ©jÃ  de l'augmentation pour simuler :
- â˜ï¸ Brouillard
- ğŸŒ§ï¸ Pluie
- â„ï¸ Neige
- ğŸŒ™ Conditions nocturnes
- ğŸ’¨ Flou de mouvement
- ğŸ”† Variations de luminositÃ©

Pour activer l'augmentation intensive pendant l'entraÃ®nement, modifiez `data/dataset.py` :

```python
from data.dataset import get_heavy_augmentation

# Dans train.py, remplacer get_training_augmentation par :
transform = get_heavy_augmentation(image_size)
```

### Phase 3 : Fine-tuning spÃ©cifique

Pour adapter Ã  des conditions trÃ¨s spÃ©cifiques :

1. Collectez des donnÃ©es dans ces conditions dans CARLA
2. Fine-tunez le modÃ¨le prÃ©-entraÃ®nÃ© :

```bash
python training/train.py \
    --model enet \
    --resume checkpoints/enet_binary_v1_best.pth \
    --train_images data/extreme_conditions/images \
    --train_masks data/extreme_conditions/masks \
    --epochs 20 \
    --lr 1e-5 \
    --experiment_name enet_finetuned_extreme
```

## ğŸ“ˆ MÃ©triques d'Ã©valuation

Le systÃ¨me calcule :

- **mIoU** (mean Intersection over Union) : MÃ©trique principale
- **Pixel Accuracy** : PrÃ©cision globale
- **Dice Coefficient** : Alternative Ã  l'IoU
- **IoU par classe** : Performance pour Traversable et ObstruÃ©

### Objectifs de performance

- **mIoU > 0.85** : Excellent
- **mIoU > 0.80** : TrÃ¨s bon
- **mIoU > 0.75** : Bon
- **mIoU < 0.70** : NÃ©cessite amÃ©lioration

## ğŸ’¡ Conseils pour de meilleurs rÃ©sultats

1. **QuantitÃ© de donnÃ©es** :
   - Minimum : 500 images
   - RecommandÃ© : 2000-5000 images
   - Optimal : 10000+ images

2. **DiversitÃ©** :
   - Collectez dans diffÃ©rentes cartes CARLA
   - Variez les conditions mÃ©tÃ©o
   - Incluez jour et nuit
   - Variez les scÃ©narios (urbain, autoroute, rural)

3. **Ã‰quilibrage des classes** :
   - Utilisez `--weighted_loss` si dÃ©sÃ©quilibre
   - VÃ©rifiez la distribution avec `visualize_class_distribution()`

4. **Optimisation** :
   - ENet : ~60 FPS sur GPU moderne (RTX 3060+)
   - U-Net : ~30 FPS sur GPU moderne
   - Augmentez `batch_size` si vous avez plus de VRAM

5. **Checkpoints** :
   - Sauvegardez rÃ©guliÃ¨rement
   - Gardez le meilleur modÃ¨le (`_best.pth`)
   - ExpÃ©rimentez avec diffÃ©rents hyperparamÃ¨tres

## ğŸ› DÃ©pannage

### CUDA Out of Memory

```bash
# RÃ©duire la taille du batch
--batch_size 2

# RÃ©duire la taille des images
--image_size 256
```

### CARLA ne se connecte pas

```bash
# VÃ©rifier que CARLA est lancÃ©
ps aux | grep Carla

# VÃ©rifier le port
--port 2000

# Augmenter le timeout dans le code si connexion lente
```

### Mauvaises performances

1. VÃ©rifier la qualitÃ© des donnÃ©es
2. Augmenter le nombre d'epochs
3. Essayer diffÃ©rents learning rates
4. Utiliser `--weighted_loss`
5. Collecter plus de donnÃ©es

## ğŸ“§ Support

Pour toute question ou problÃ¨me :
- Consultez les logs TensorBoard
- VÃ©rifiez les mÃ©triques d'Ã©valuation
- Visualisez les prÃ©dictions

## ğŸ“ Citation

```bibtex
@misc{segmentation_carla_2026,
  title={Binary Semantic Segmentation for Autonomous Driving with CARLA},
  author={Votre Nom},
  year={2026},
  url={https://github.com/votre-repo}
}
```

## ğŸ“„ Licence

Ce projet est sous licence MIT.

---

**Bon courage pour votre projet! ğŸš—ğŸ¤–**

Pour toute amÃ©lioration future, ce projet est conÃ§u pour Ãªtre facilement extensible. La sÃ©paration claire entre reconnaissance multi-classe et classification binaire permet d'adapter facilement le systÃ¨me Ã  d'autres types de segmentation.